{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280763f6-477b-4b63-a389-ac9b52ba8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ae4680-beb1-46fe-9a32-62e9120959ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idQuestion</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shiq1</td>\n",
       "      <td>Do you offer free shipping?</td>\n",
       "      <td>Yes, we offer free shipping for orders above a...</td>\n",
       "      <td>shipping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shiq2</td>\n",
       "      <td>How long does shipping take?</td>\n",
       "      <td>Standard shipping takes 5-7 business days, whi...</td>\n",
       "      <td>shipping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idQuestion                      question  \\\n",
       "0      shiq1   Do you offer free shipping?   \n",
       "1      shiq2  How long does shipping take?   \n",
       "\n",
       "                                              answer     label  \n",
       "0  Yes, we offer free shipping for orders above a...  shipping  \n",
       "1  Standard shipping takes 5-7 business days, whi...  shipping  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('faq_dataset.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f5f87b-8b78-4a59-b046-2656b7e6da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f68dd-b1ed-48ac-b46c-b020ab85ce46",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5f1d07-c009-49b5-b3fa-93b8dcc22e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['question']\n",
    "y = df['label']\n",
    "\n",
    "# Encoder les labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(y)\n",
    "y_encoded = df['label_encoded']\n",
    "\n",
    "# strati number\n",
    "k = 5 \n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Init tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "folds = []\n",
    "for train_index, val_index in skf.split(X, y_encoded):\n",
    "    # Extracting data données for current fold \n",
    "    train_texts, val_texts = X.iloc[train_index], X.iloc[val_index]\n",
    "    train_labels, val_labels = y_encoded.iloc[train_index], y_encoded.iloc[val_index]\n",
    "\n",
    "    # Tokenization\n",
    "    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # Sauvegarder le fold\n",
    "    folds.append((train_encodings, train_labels, val_encodings, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68d031-3c64-4e1b-848b-65e37364911f",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcf0804-adc3-4618-9982-86471717f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class Dataset \n",
    "class FAQDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbee9306-d0e1-40dc-829b-4c09d7cddbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg first fold\n",
    "train_encodings, train_labels, val_encodings, val_labels = folds[0]\n",
    "\n",
    "train_dataset = FAQDataset(train_encodings, train_labels)\n",
    "val_dataset = FAQDataset(val_encodings, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56c8cc-cba5-48f1-9951-50a5f2d2b5b4",
   "metadata": {},
   "source": [
    "## setting Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e80dab-314d-4d9d-962d-ce8841857ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mbock/venvs/transformers/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Loading model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_encoder.classes_))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "def train_model(train_loader, model, optimizer, device):\n",
    "    model.train()  # Mode entraînement\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Préparer les données pour le GPU\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    return avg_train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67796f3b-1b6a-435a-a9d6-38c2df4d5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(val_loader, model, device):\n",
    "    # Mode evaluation\n",
    "    model.eval()  \n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        # data preparation for device\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculer les prédictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b8516d-c37d-4f7d-8323-eba81045c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 6/6 [01:53<00:00, 18.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3377, Validation Accuracy: 0.9783\n",
      "\n",
      "Training Fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:12<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4145, Validation Accuracy: 0.8913\n",
      "\n",
      "Training Fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2789, Validation Accuracy: 0.9130\n",
      "\n",
      "Training Fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2832, Validation Accuracy: 0.9565\n",
      "\n",
      "Training Fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1550, Validation Accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Boucle sur les folds\n",
    "for fold, (train_encodings, train_labels, val_encodings, val_labels) in enumerate(folds):\n",
    "    print(f\"\\nTraining Fold {fold + 1}/{k}...\")\n",
    "\n",
    "    # Préparer les datasets et loaders\n",
    "    train_dataset = FAQDataset(train_encodings, train_labels)\n",
    "    val_dataset = FAQDataset(val_encodings, val_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    train_loss = train_model(train_loader, model, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Évaluer le modèle\n",
    "    val_loss, val_accuracy = evaluate_model(val_loader, model, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9386533-d351-4755-a670-71c944538685",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65bf0ec7-6ce2-4b61-83f0-ae18acd9f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:\n",
      "  Moyenne : 0.2939\n",
      "  Écart-type : 0.0850\n",
      "\n",
      "Validation Accuracy:\n",
      "  Moyenne : 0.9435\n",
      "  Écart-type : 0.0353\n"
     ]
    }
   ],
   "source": [
    "# folds results\n",
    "validation_losses = [0.3377, 0.4145, 0.2789, 0.2832, 0.1550]\n",
    "validation_accuracies = [0.9783, 0.8913, 0.9130, 0.9565, 0.9783]\n",
    "\n",
    "# Compute metrics\n",
    "avg_loss = np.mean(validation_losses)\n",
    "std_loss = np.std(validation_losses)\n",
    "\n",
    "avg_accuracy = np.mean(validation_accuracies)\n",
    "std_accuracy = np.std(validation_accuracies)\n",
    "\n",
    "# displays results\n",
    "print(\"Validation Loss:\")\n",
    "print(f\"  Moyenne : {avg_loss:.4f}\")\n",
    "print(f\"  Écart-type : {std_loss:.4f}\")\n",
    "print(\"\\nValidation Accuracy:\")\n",
    "print(f\"  Moyenne : {avg_accuracy:.4f}\")\n",
    "print(f\"  Écart-type : {std_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d49189d-9cb3-4c86-85c0-9d9060611a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.txt',\n",
       " './model/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du modèle\n",
    "model.save_pretrained(\"./model\")\n",
    "tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c1c4a-2f1a-4c62-85d8-50aa3bf56215",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
